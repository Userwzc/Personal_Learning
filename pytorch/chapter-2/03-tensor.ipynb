{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1., -1.],\n",
      "        [-1.,  1.]]) torch.float32 torch.Size([2, 2])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]]) torch.int64 torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = [[1.,-1.],[-1.,1.]]\n",
    "b = [[1,2,3],[4,5,6]]\n",
    "#  (function) def tensor(\n",
    "#     data: Any,\n",
    "#     dtype: dtype | None = None,\n",
    "#     device: DeviceLikeType | None = None,\n",
    "#     requires_grad: bool = False,\n",
    "#     pin_memory: bool = False\n",
    "# ) -> Tensor\n",
    "tensor_a = torch.tensor(a)\n",
    "tensor_b = torch.tensor(b)\n",
    "print(tensor_a,tensor_a.dtype,tensor_a.shape)\n",
    "print(tensor_b,tensor_b.dtype ,tensor_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]]) torch.int64 torch.Size([2, 3])\n",
      "tensor([[0, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "c = np.array([[1,2,3],[4,5,6]])\n",
    "tensor_c = torch.from_numpy(c)\n",
    "# 需要特别注意的是，创建的tensor和原array共享同一块内存，当修改其中一个的值时，另一个的值也会发生改变\n",
    "print(tensor_c,tensor_c.dtype,tensor_c.shape)\n",
    "c[0,0] = 0\n",
    "print(tensor_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]]) \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "139778514466080 \n",
      " 139778514466080\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "o_t = torch.tensor([1.])\n",
    "t = torch.zeros((3,3),out=o_t)\n",
    "print(t,\"\\n\",o_t)\n",
    "print(id(t),\"\\n\",id(o_t))\n",
    "print(t.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0]]) torch.int64\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]]) torch.float32\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]]) torch.int64\n",
      "tensor([[7, 7, 7, 7],\n",
      "        [7, 7, 7, 7],\n",
      "        [7, 7, 7, 7],\n",
      "        [7, 7, 7, 7]]) torch.int64\n",
      "tensor([[8, 8, 8],\n",
      "        [8, 8, 8]]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([[1,2,3],[4,5,6]])\n",
    "t2 = torch.zeros_like(t1)\n",
    "print(t2,t2.dtype)\n",
    "\n",
    "t3 = torch.ones((2,2))\n",
    "t4 = torch.ones_like(t1)\n",
    "print(t3,t3.dtype)\n",
    "print(t4,t4.dtype)\n",
    "\n",
    "t5 = torch.full((4,4),7)\n",
    "print(t5,t5.dtype)\n",
    "\n",
    "t6 = torch.full_like(t1,8)\n",
    "print(t6,t6.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 2, 4, 6, 8]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "t7 = torch.arange(0,10,2)  # 步长\n",
    "print(t7,t7.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000,  2.5000,  5.0000,  7.5000, 10.0000]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "t8 = torch.linspace(0,10,5)  # 个数\n",
    "print(t8,t8.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000e+00, 3.1623e+02, 1.0000e+05, 3.1623e+07, 1.0000e+10]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "t9 = torch.logspace(0,10,5)  # 个数,默认底数为10\n",
    "print(t9,t9.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]]) torch.float32\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.]]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "# 单位对角矩阵\n",
    "l1 = torch.eye(3)\n",
    "print(l1,l1.dtype)\n",
    "l2 = torch.eye(3,4)\n",
    "print(l2,l2.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7.3948e-13,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -8.6198e-05,  4.5604e-41]]) torch.float32\n",
      "tensor([[7.2520e-13, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 7.2929e-13, 0.0000e+00]]) torch.float32\n",
      "tensor([[7.4437e-13, 0.0000e+00, 4.4842e-44],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "# torch.empty(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor\n",
    "# 返回一个未初始化的张量，包括size大小和dtype类型\n",
    "l3 = torch.empty(2,3)\n",
    "print(l3,l3.dtype)\n",
    "\n",
    "# torch.empty_like(input, dtype=None, layout=None, device=None, requires_grad=False) → Tensor\n",
    "# 返回一个未初始化的张量，包括input的size和dtype类型\n",
    "l4 = torch.empty_like(l3)\n",
    "print(l4,l4.dtype)\n",
    "\n",
    "# torch.empty_strided(size, stride, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor\n",
    "# 返回一个未初始化的张量，包括size大小和dtype类型，stride步长\n",
    "l5 = torch.empty_strided((2,3),(1,2))\n",
    "print(l5,l5.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.6536, -1.7524, -0.3140]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "# 依概率分布创建\n",
    "# torch.normal(mean, std, out=None) → Tensor\n",
    "# mean为张量，std为张量\n",
    "n1 = torch.normal(torch.zeros(3),torch.ones(3))\n",
    "print(n1,n1.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3955, 0.5670, 0.7966],\n",
      "        [0.4293, 0.4432, 0.6576],\n",
      "        [0.4699, 0.0670, 0.2476]]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "n2 = torch.rand((3,3))  # 0-1均匀分布\n",
    "print(n2,n2.dtype)\n",
    "\n",
    "# torch.rand_like()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7, 1, 8],\n",
      "        [3, 2, 6],\n",
      "        [1, 8, 2]]) torch.int64\n",
      "tensor([[9, 8, 8],\n",
      "        [1, 7, 2],\n",
      "        [4, 6, 4]]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "n3 = torch.randint(0,10,(3,3))  # 0-10均匀分布\n",
    "print(n3,n3.dtype)\n",
    "\n",
    "n4 = torch.randint_like(n3,10)\n",
    "print(n4,n4.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8, 3, 6, 2, 5, 7, 0, 4, 1, 9]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "n5 = torch.randperm(10) # 随机排列\n",
    "print(n5,n5.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [0., 1., 1.]]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "n6 = torch.bernoulli(torch.full((3,3),0.5))  # 伯努利分布 （0-1分布）\n",
    "print(n6,n6.dtype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
